{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using cifar10 dataset\n",
    "\n",
    "60000 tiny images of 10 classes. \n",
    "Uses up LOTTTTTT of CPU, therefore **TODO**: launch the same on GPU-enabled server at AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# STEP 1: Import Data\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "(X_train, y_train),(X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above SHAPE tells us:\n",
    "    - Images are 32 x 32\n",
    "    - Color images (bc of 3 = RGB = depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#STEP 2: Visualize some of the data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(20,5))\n",
    "for i in range(36): # total of 36 images\n",
    "    ax = fig.add_subplot(3,12, i+1, xticks=[], yticks=[]) # 3 rows, 12 columns\n",
    "    ax.imshow(np.squeeze(X_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STEP 3: Preprocessing (Rescale to [0,1] instead of [0,255])\n",
    "\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#STEP 4: Break data into test, train, validation sets\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#One-hot encoding LABELS\n",
    "numOfLabels = len(np.unique(y_train))\n",
    "y_train = np_utils.to_categorical(y_train, numOfLabels)\n",
    "y_test = np_utils.to_categorical(y_test, numOfLabels)\n",
    "\n",
    "#Train and validation split\n",
    "(X_train, X_validation) = X_train[5000:], X_train[:5000]\n",
    "(y_train, y_validation) = y_train[5000:], y_train[:5000]\n",
    "\n",
    "#Shape of all 3 (train, test, validation)\n",
    "print(\"Train size = \", X_train.shape[0])\n",
    "print(\"Test size = \", X_test.shape[0])\n",
    "print(\"Validate size = \", X_validation.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape = X_train.shape[1:]))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(numOfLabels, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "chkpoint = ModelCheckpoint(filepath=\"MLP.weights.best.hdf5\", verbose=1, save_best_only=True)\n",
    "hist = model.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_validation, y_validation), callbacks=[chkpoint], verbose=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluation(X_test, y_test, verbose=0)\n",
    "accuracy = score[1] *100\n",
    "\n",
    "print(\"Test accuracy = \", accuracy, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP is NOT a good idea for multiple reasons:\n",
    "- Parameters are OVER 3 million (ie too much memory consumption)\n",
    "- Test accuracy is faaaaaaaaaaaaaar low!\n",
    "\n",
    "**Therefore, let's give CNN a try ---**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', input_shape=(32,32,3)))\n",
    "cnn.add(MaxPooling2D(pool_size=2))\n",
    "cnn.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=2))\n",
    "cnn.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=2))\n",
    "cnn.add(Dropout(0.3))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(500, activation='relu'))\n",
    "cnn.add(Dropout(0.4))\n",
    "cnn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chkpt = ModelCheckpoint(filepath=\"CNN.weights.best.hdf5\",verbose=1,save_only_best=True)\n",
    "hist = cnn.fit(X_train, y_train, callbacks=[chkpt], validation_data=(X_validation, y_validation), batch_size=32, epochs=100, shuffle=True, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn.load_weights(\"CNN.weights.best.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = cnn.evaluation(X_test, y_test, verbose=0)\n",
    "accuracy = score[1]* 100\n",
    "\n",
    "print (\"Test accuracy (using CNN) = \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
